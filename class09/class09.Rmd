---
title: "Class 9"
author: "Serina Huang"
date: "October 30, 2018"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Section 1.
## Preparing the data
```{r}
url <- "https://bioboot.github.io/bimm143_S18/class-material/WisconsinCancer.csv"
wisc.df <- read.csv(url)
head(wisc.df)
# Convert columns 3 to 32 to a matrix
wisc.data <- as.matrix(wisc.df[,3:32])
head(wisc.data)
```

After checking the data, we find that the last column is funky. The takeaway here is to be suspicious of your data.
```{r}
# Set row names of wisc.data to patient ID
row.names(wisc.data) <- wisc.df$id
head(wisc.data)
```

How many tumors are malignant and how many are benign?
```{r}
table(wisc.df$diagnosis)
diagnosis <- as.numeric( wisc.df$diagnosis == "M" )
# See if the numeric vector adds up to 212, as found by table
sum(diagnosis)
```

## Exploratory data analysis
Q1. How many observations are in this dataset?
```{r}
nrow(wisc.data)
```

Q2. How many variables/features in the data are suffixed with _mean?
```{r}
col_names <- colnames(wisc.data)
mean_vec <- grep("_mean", col_names)
col_names[mean_vec]
length(mean_vec)
```

There are `r length(mean_vec)` mean measurements in this dataset.

Q3. How many of the observations have a malignant diagnosis?
```{r}
table(wisc.df$diagnosis)
```

# Section 2.
## Performing PCA
Check the mean of the features (columns) of `wisc.data` to determine if the data needs to be scaled.
```{r}
# Check mean of each column
colMeans(wisc.data)
# Can also use the following. The 2 here indicates columns
apply(wisc.data, 2, mean)
# Check standard deviation of each column
apply(wisc.data, 2, sd)
```

The mean and standard deviation of columns are pretty different! It's probably a good idea to scale the features when doing PCA.
```{r}
wisc.pr <- prcomp(wisc.data, scale = TRUE)
z <- summary(wisc.pr)
z
per_var <- round( z$sdev^2 / sum(z$sdev^2) * 100 )
```

Q4. What proportion of original variance is captured by the first principal components (PC1)?
44.27%.

Q5. How many PCs are required to describe at least 70% of variance in the data?
3.

Q6. How many PCs are required to describe at least 90% of variance in the data?
7.

## Interpreting PCA results
```{r}
biplot(wisc.pr)
```

Q7. What stands out to you about this plot? Is it easy or difficult to understand? Why?
Rownames are used as the plotting character for biplots, which can make trends hard to see.

We can generate a more standard scatter plot of each observation along principal components 1 and 2 (i.e. a plot of PC1 vs PC2 available as the first two columns of wisc.pr$x) and color the points by the diagnosis (available in the diagnosis vector you created earlier).
```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2])
plot(wisc.pr$x[,1], wisc.pr$x[,2], col = diagnosis)
# Why did my points disappear? Default palette plots white points for 0
palette()
plot(wisc.pr$x[,1], wisc.pr$x[,2], col = diagnosis + 1, xlab = "PC1", ylab = "PC2")
```

Q8. Repeat the same for PC1 and PC3. What do you notice?
```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,3], col = diagnosis + 1, xlab = "PC1", ylab = "PC3")
```

Because PC2 explains more variance in the original data than PC3, you can see that the first plot has a cleaner cut separating the two subgroups.

Overall, the plots indicate that PC1 is capturing a separation of malignant from benign samples. This is an important and interesting result worthy of further exploration - as we will do in the next sections!

## Variance explained
Calculate variance of each PC by squaring `sdev` component of `wisc.pr`.
```{r}
pr.var <- wisc.pr$sdev ^ 2
pve <- pr.var / sum(pr.var)
plot(pve, typ = "o", xlab = "Principle Component", ylab = "Proportion of Variance Explained", ylim = c(0,1))
```

Can we plot the scree plot as a barplot?
```{r}
barplot( pve, ylab = "Percent of Variance Explained", names.arg = paste0("PC",1:length(pve)), las = 2, axes = FALSE )
# To the left, add axis with tick marks of actual values, i.e. data-driven axis
axis(2, at = pve, labels = round(pve,2)*100 )
```

Use `cumsum()` to create a plot of cumulative proportion of variance explained.
```{r}
cum.var <- cumsum(pve)
plot(cum.var, typ = "o", xlab = "Principal Component", ylab = "Cumulative Proportion of Variance Explained")
```

# Section 3.
## Hierarchical clustering of case data
Q11. Using the `plot()` function, what is the height at which the clustering model has 4 clusters?
```{r}
data.scaled <- scale(wisc.data)
data.dist <- dist(data.scaled)
head(data.dist)
wisc.hclust <- hclust(data.dist, method = "complete")
plot(wisc.hclust)
```

## Selecting number of clusters
We want to ask the question: does hierarchical clustering give us any new information in this case?
```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, k = 4)
table(wisc.hclust.clusters)
```

There's one group (cluster) with 177 points, one with 7, one with 383, and one with 2. Compare this with actual diagnosis. Cross-tabulation:
```{r}
table(wisc.hclust.clusters, diagnosis)
```

Q12. Can you find a better cluster vs. diagnosis match by cutting into a different number of clusters (between 2 and 10)?
```{r}
wisc.hclust.clusters5 <- cutree(wisc.hclust, k = 5)
```

# Section 5.
## Clustering on PCA results
Earlier we found that a minumum of 7 clusters is required to describe at least 90% of variability in the data. Create a hierarchical clustering model with complete linkage.
```{r}
d.pr <- dist(wisc.pr$x[, 1:7])
wisc.pr.hclust <- hclust(d.pr, method = "complete")
plot(wisc.pr.hclust)
```

Let's see how well hierarchical clustering of PCA works.
```{r}
wisc.pr.hclust.clusters <- cutree(wisc.pr.hclust, k = 4)
table(wisc.pr.hclust.clusters, diagnosis)
# Compare with hierarchical clustering NOT from PCA
table(wisc.hclust.clusters, diagnosis)
```

Q14. How well does the newly created model with four clusters separate out the two diagnoses?


# Section 7.
## Predicting Malignancy of New Samples with Our PCR Model
```{r}
url2 <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url2)
npc <- predict(wisc.pr, newdata = new)

plot(wisc.pr$x[,1:2], col = diagnosis + 1)
points(npc[,1], npc[,2], col = "blue", pch = 16, cex = 2)
```

How else can we use this besides disease prediction?